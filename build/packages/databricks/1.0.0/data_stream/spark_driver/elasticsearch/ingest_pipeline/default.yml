---
description: Pipeline for parsing Apache Spark driver metrics.
processors:
  - set:
      field: ecs.version
      value: '8.11.0'
  - rename:
      field: jolokia.metrics
      target_field: databricks
      ignore_missing: true
  - set:
      field: event.type
      value: [info]
  - set:
      field: event.kind
      value: metric
  - set:
      field: event.module
      value: databricks
  - script:
      lang: painless
      description: This script will add the name of application under key 'driver/executor.application_name' and executor id under 'databricks.executor.id'
      if: ctx?.databricks?.mbean?.contains("name=worker.") == false &&
          ctx?.databricks?.mbean?.contains("name=worker.") == false &&
          ctx?.databricks?.mbean?.contains("name=application.") == false 
      source: >-
        def bean_name = ctx.databricks.mbean.toString().splitOnToken("=")[1];
        def app_name = bean_name.splitOnToken(".")[0];
        def executor_id = bean_name.splitOnToken(".")[1];
        if (executor_id == "driver") {
          ctx.databricks.driver.application_name = app_name;
        } else {
          ctx.databricks.executors.application_name = app_name;
          ctx.databricks.executors.id = executor_id;
        }
  - rename:
      field: databricks.mbean
      target_field: databricks.driver.mbean
      ignore_missing: true
  - remove:
      field:
        - jolokia
      ignore_failure: true
on_failure:
  - set:
      field: error.message
      value: '{{ _ingest.on_failure_message }}'
